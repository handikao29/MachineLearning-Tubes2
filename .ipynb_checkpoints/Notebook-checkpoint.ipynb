{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(b'sunny', 85., 85., b'FALSE', b'no')\n",
      " (b'sunny', 80., 90., b'TRUE', b'no')\n",
      " (b'overcast', 83., 86., b'FALSE', b'yes')\n",
      " (b'rainy', 70., 96., b'FALSE', b'yes')\n",
      " (b'rainy', 68., 80., b'FALSE', b'yes')\n",
      " (b'rainy', 65., 70., b'TRUE', b'no')\n",
      " (b'overcast', 64., 65., b'TRUE', b'yes')\n",
      " (b'sunny', 72., 95., b'FALSE', b'no')\n",
      " (b'sunny', 69., 70., b'FALSE', b'yes')\n",
      " (b'rainy', 75., 80., b'FALSE', b'yes')\n",
      " (b'sunny', 75., 70., b'TRUE', b'yes')\n",
      " (b'overcast', 72., 90., b'TRUE', b'yes')\n",
      " (b'overcast', 81., 75., b'FALSE', b'yes')\n",
      " (b'rainy', 71., 91., b'TRUE', b'no')]\n",
      "Dataset: weather\n",
      "\toutlook's type is nominal, range is ('sunny', 'overcast', 'rainy')\n",
      "\ttemperature's type is numeric\n",
      "\thumidity's type is numeric\n",
      "\twindy's type is nominal, range is ('TRUE', 'FALSE')\n",
      "\tplay's type is nominal, range is ('yes', 'no')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from scipy.io import arff\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Read the train dataset from csv file\n",
    "data, meta = arff.loadarff(\"weather.arff\")\n",
    "print(data)\n",
    "print(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 85 85 0]\n",
      " [2 80 90 1]\n",
      " [0 83 86 0]\n",
      " [1 70 96 0]\n",
      " [1 68 80 0]\n",
      " [1 65 70 1]\n",
      " [0 64 65 1]\n",
      " [2 72 95 0]\n",
      " [2 69 70 0]\n",
      " [1 75 80 0]\n",
      " [2 75 70 1]\n",
      " [0 72 90 1]\n",
      " [0 81 75 0]\n",
      " [1 71 91 1]]\n",
      "[0 0 1 1 1 0 1 0 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train_csv = pd.read_csv(\"weather.csv\",header=0)\n",
    "array = np.array(train_csv)\n",
    "X = array[:,:-1]\n",
    "le = LabelEncoder()\n",
    "A = le.fit_transform(X[:,0])\n",
    "B = le.fit_transform(X[:,-1])\n",
    "y = le.fit_transform(array[:,-1])\n",
    "for i in range(0,len(X)):\n",
    "    X[i,0] = A[i]\n",
    "    X[i,-1] = B[i]\n",
    "    \n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 81, 75, 0],\n",
       "       [0, 64, 65, 1],\n",
       "       [2, 69, 70, 0],\n",
       "       [0, 83, 86, 0],\n",
       "       [2, 75, 70, 1],\n",
       "       [1, 65, 70, 1],\n",
       "       [0, 72, 90, 1],\n",
       "       [1, 71, 91, 1],\n",
       "       [2, 80, 90, 1],\n",
       "       [2, 85, 85, 0],\n",
       "       [1, 68, 80, 0],\n",
       "       [1, 75, 80, 0]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=10)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.2574 - acc: 1.0000\n",
      "Epoch 2/150\n",
      "12/12 [==============================] - 0s 251us/step - loss: 0.2559 - acc: 1.0000\n",
      "Epoch 3/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2545 - acc: 1.0000\n",
      "Epoch 4/150\n",
      "12/12 [==============================] - 0s 251us/step - loss: 0.2530 - acc: 1.0000\n",
      "Epoch 5/150\n",
      "12/12 [==============================] - 0s 333us/step - loss: 0.2515 - acc: 1.0000\n",
      "Epoch 6/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2501 - acc: 1.0000\n",
      "Epoch 7/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2486 - acc: 1.0000\n",
      "Epoch 8/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2472 - acc: 1.0000\n",
      "Epoch 9/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2458 - acc: 1.0000\n",
      "Epoch 10/150\n",
      "12/12 [==============================] - 0s 417us/step - loss: 0.2444 - acc: 0.9167\n",
      "Epoch 11/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2431 - acc: 0.9167\n",
      "Epoch 12/150\n",
      "12/12 [==============================] - 0s 334us/step - loss: 0.2418 - acc: 0.9167\n",
      "Epoch 13/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2405 - acc: 0.9167\n",
      "Epoch 14/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2393 - acc: 0.8333\n",
      "Epoch 15/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2381 - acc: 0.8333\n",
      "Epoch 16/150\n",
      "12/12 [==============================] - 0s 251us/step - loss: 0.2369 - acc: 0.8333\n",
      "Epoch 17/150\n",
      "12/12 [==============================] - 0s 168us/step - loss: 0.2358 - acc: 0.8333\n",
      "Epoch 18/150\n",
      "12/12 [==============================] - 0s 251us/step - loss: 0.2348 - acc: 0.8333\n",
      "Epoch 19/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2337 - acc: 0.8333\n",
      "Epoch 20/150\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2327 - acc: 0.8333\n",
      "Epoch 21/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2317 - acc: 0.8333\n",
      "Epoch 22/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2307 - acc: 0.8333\n",
      "Epoch 23/150\n",
      "12/12 [==============================] - 0s 417us/step - loss: 0.2297 - acc: 0.8333\n",
      "Epoch 24/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2288 - acc: 0.8333\n",
      "Epoch 25/150\n",
      "12/12 [==============================] - 0s 416us/step - loss: 0.2279 - acc: 0.8333\n",
      "Epoch 26/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2271 - acc: 0.8333\n",
      "Epoch 27/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2263 - acc: 0.8333\n",
      "Epoch 28/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2256 - acc: 0.8333\n",
      "Epoch 29/150\n",
      "12/12 [==============================] - 0s 166us/step - loss: 0.2249 - acc: 0.8333\n",
      "Epoch 30/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2243 - acc: 0.8333\n",
      "Epoch 31/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2237 - acc: 0.8333\n",
      "Epoch 32/150\n",
      "12/12 [==============================] - 0s 417us/step - loss: 0.2232 - acc: 0.8333\n",
      "Epoch 33/150\n",
      "12/12 [==============================] - 0s 498us/step - loss: 0.2227 - acc: 0.8333\n",
      "Epoch 34/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2222 - acc: 0.8333\n",
      "Epoch 35/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2218 - acc: 0.8333\n",
      "Epoch 36/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2214 - acc: 0.8333\n",
      "Epoch 37/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2210 - acc: 0.8333\n",
      "Epoch 38/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2206 - acc: 0.8333\n",
      "Epoch 39/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2203 - acc: 0.8333\n",
      "Epoch 40/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2199 - acc: 0.8333\n",
      "Epoch 41/150\n",
      "12/12 [==============================] - 0s 166us/step - loss: 0.2196 - acc: 0.8333\n",
      "Epoch 42/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2193 - acc: 0.8333\n",
      "Epoch 43/150\n",
      "12/12 [==============================] - 0s 335us/step - loss: 0.2190 - acc: 0.8333\n",
      "Epoch 44/150\n",
      "12/12 [==============================] - 0s 251us/step - loss: 0.2187 - acc: 0.8333\n",
      "Epoch 45/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2185 - acc: 0.8333\n",
      "Epoch 46/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2182 - acc: 0.9167\n",
      "Epoch 47/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2180 - acc: 0.9167\n",
      "Epoch 48/150\n",
      "12/12 [==============================] - 0s 166us/step - loss: 0.2178 - acc: 0.9167\n",
      "Epoch 49/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2176 - acc: 0.9167\n",
      "Epoch 50/150\n",
      "12/12 [==============================] - 0s 165us/step - loss: 0.2174 - acc: 0.9167\n",
      "Epoch 51/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2172 - acc: 0.9167\n",
      "Epoch 52/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2170 - acc: 0.9167\n",
      "Epoch 53/150\n",
      "12/12 [==============================] - 0s 333us/step - loss: 0.2168 - acc: 0.9167\n",
      "Epoch 54/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2167 - acc: 1.0000\n",
      "Epoch 55/150\n",
      "12/12 [==============================] - 0s 166us/step - loss: 0.2165 - acc: 1.0000\n",
      "Epoch 56/150\n",
      "12/12 [==============================] - 0s 166us/step - loss: 0.2164 - acc: 1.0000\n",
      "Epoch 57/150\n",
      "12/12 [==============================] - 0s 166us/step - loss: 0.2162 - acc: 1.0000\n",
      "Epoch 58/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2161 - acc: 1.0000\n",
      "Epoch 59/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2160 - acc: 1.0000\n",
      "Epoch 60/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2159 - acc: 1.0000\n",
      "Epoch 61/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2157 - acc: 1.0000\n",
      "Epoch 62/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2156 - acc: 1.0000\n",
      "Epoch 63/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2155 - acc: 1.0000\n",
      "Epoch 64/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2154 - acc: 1.0000\n",
      "Epoch 65/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2153 - acc: 1.0000\n",
      "Epoch 66/150\n",
      "12/12 [==============================] - 0s 499us/step - loss: 0.2152 - acc: 1.0000\n",
      "Epoch 67/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2152 - acc: 1.0000\n",
      "Epoch 68/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2151 - acc: 1.0000\n",
      "Epoch 69/150\n",
      "12/12 [==============================] - 0s 166us/step - loss: 0.2150 - acc: 1.0000\n",
      "Epoch 70/150\n",
      "12/12 [==============================] - 0s 249us/step - loss: 0.2149 - acc: 1.0000\n",
      "Epoch 71/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2148 - acc: 1.0000\n",
      "Epoch 72/150\n",
      "12/12 [==============================] - 0s 252us/step - loss: 0.2148 - acc: 1.0000\n",
      "Epoch 73/150\n",
      "12/12 [==============================] - 0s 333us/step - loss: 0.2147 - acc: 1.0000\n",
      "Epoch 74/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2146 - acc: 1.0000\n",
      "Epoch 75/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2146 - acc: 1.0000\n",
      "Epoch 76/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2145 - acc: 1.0000\n",
      "Epoch 77/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2145 - acc: 0.9167\n",
      "Epoch 78/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2144 - acc: 0.9167\n",
      "Epoch 79/150\n",
      "12/12 [==============================] - 0s 333us/step - loss: 0.2143 - acc: 0.9167\n",
      "Epoch 80/150\n",
      "12/12 [==============================] - 0s 417us/step - loss: 0.2143 - acc: 0.9167\n",
      "Epoch 81/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2142 - acc: 0.9167\n",
      "Epoch 82/150\n",
      "12/12 [==============================] - 0s 166us/step - loss: 0.2142 - acc: 0.9167\n",
      "Epoch 83/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2141 - acc: 0.9167\n",
      "Epoch 84/150\n",
      "12/12 [==============================] - 0s 251us/step - loss: 0.2141 - acc: 0.9167\n",
      "Epoch 85/150\n",
      "12/12 [==============================] - 0s 333us/step - loss: 0.2140 - acc: 0.9167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/150\n",
      "12/12 [==============================] - 0s 333us/step - loss: 0.2140 - acc: 0.9167\n",
      "Epoch 87/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2139 - acc: 0.9167\n",
      "Epoch 88/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2139 - acc: 0.9167\n",
      "Epoch 89/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2138 - acc: 0.9167\n",
      "Epoch 90/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2138 - acc: 0.9167\n",
      "Epoch 91/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2137 - acc: 0.9167\n",
      "Epoch 92/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2137 - acc: 0.9167\n",
      "Epoch 93/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2137 - acc: 0.9167\n",
      "Epoch 94/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2136 - acc: 0.9167\n",
      "Epoch 95/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2136 - acc: 0.9167\n",
      "Epoch 96/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2135 - acc: 0.9167\n",
      "Epoch 97/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2135 - acc: 0.9167\n",
      "Epoch 98/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2135 - acc: 0.9167\n",
      "Epoch 99/150\n",
      "12/12 [==============================] - 0s 333us/step - loss: 0.2134 - acc: 0.9167\n",
      "Epoch 100/150\n",
      "12/12 [==============================] - 0s 500us/step - loss: 0.2134 - acc: 0.9167\n",
      "Epoch 101/150\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2134 - acc: 0.9167\n",
      "Epoch 102/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2133 - acc: 0.9167\n",
      "Epoch 103/150\n",
      "12/12 [==============================] - 0s 249us/step - loss: 0.2133 - acc: 0.9167\n",
      "Epoch 104/150\n",
      "12/12 [==============================] - 0s 249us/step - loss: 0.2133 - acc: 0.9167\n",
      "Epoch 105/150\n",
      "12/12 [==============================] - 0s 168us/step - loss: 0.2132 - acc: 0.9167\n",
      "Epoch 106/150\n",
      "12/12 [==============================] - 0s 166us/step - loss: 0.2132 - acc: 0.9167\n",
      "Epoch 107/150\n",
      "12/12 [==============================] - 0s 333us/step - loss: 0.2132 - acc: 0.9167\n",
      "Epoch 108/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2131 - acc: 0.9167\n",
      "Epoch 109/150\n",
      "12/12 [==============================] - 0s 417us/step - loss: 0.2131 - acc: 0.9167\n",
      "Epoch 110/150\n",
      "12/12 [==============================] - 0s 166us/step - loss: 0.2131 - acc: 0.9167\n",
      "Epoch 111/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2130 - acc: 0.9167\n",
      "Epoch 112/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2130 - acc: 0.9167\n",
      "Epoch 113/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2130 - acc: 0.9167\n",
      "Epoch 114/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2130 - acc: 0.9167\n",
      "Epoch 115/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2129 - acc: 0.9167\n",
      "Epoch 116/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2129 - acc: 0.9167\n",
      "Epoch 117/150\n",
      "12/12 [==============================] - 0s 334us/step - loss: 0.2129 - acc: 0.9167\n",
      "Epoch 118/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2128 - acc: 0.8333\n",
      "Epoch 119/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2128 - acc: 0.8333\n",
      "Epoch 120/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2128 - acc: 0.8333\n",
      "Epoch 121/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2128 - acc: 0.8333\n",
      "Epoch 122/150\n",
      "12/12 [==============================] - 0s 415us/step - loss: 0.2127 - acc: 0.8333\n",
      "Epoch 123/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2127 - acc: 0.8333\n",
      "Epoch 124/150\n",
      "12/12 [==============================] - 0s 166us/step - loss: 0.2127 - acc: 0.8333\n",
      "Epoch 125/150\n",
      "12/12 [==============================] - 0s 249us/step - loss: 0.2127 - acc: 0.7500\n",
      "Epoch 126/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2126 - acc: 0.7500\n",
      "Epoch 127/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2126 - acc: 0.7500\n",
      "Epoch 128/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2126 - acc: 0.7500\n",
      "Epoch 129/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2126 - acc: 0.7500\n",
      "Epoch 130/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2125 - acc: 0.7500\n",
      "Epoch 131/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2125 - acc: 0.7500\n",
      "Epoch 132/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2125 - acc: 0.7500\n",
      "Epoch 133/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2125 - acc: 0.7500\n",
      "Epoch 134/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2125 - acc: 0.7500\n",
      "Epoch 135/150\n",
      "12/12 [==============================] - 0s 166us/step - loss: 0.2124 - acc: 0.7500\n",
      "Epoch 136/150\n",
      "12/12 [==============================] - 0s 168us/step - loss: 0.2124 - acc: 0.7500\n",
      "Epoch 137/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2124 - acc: 0.7500\n",
      "Epoch 138/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2124 - acc: 0.7500\n",
      "Epoch 139/150\n",
      "12/12 [==============================] - 0s 336us/step - loss: 0.2123 - acc: 0.7500\n",
      "Epoch 140/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2123 - acc: 0.7500\n",
      "Epoch 141/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2123 - acc: 0.7500\n",
      "Epoch 142/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2123 - acc: 0.7500\n",
      "Epoch 143/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2123 - acc: 0.7500\n",
      "Epoch 144/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2122 - acc: 0.7500\n",
      "Epoch 145/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2122 - acc: 0.7500\n",
      "Epoch 146/150\n",
      "12/12 [==============================] - 0s 250us/step - loss: 0.2122 - acc: 0.7500\n",
      "Epoch 147/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2122 - acc: 0.7500\n",
      "Epoch 148/150\n",
      "12/12 [==============================] - 0s 500us/step - loss: 0.2122 - acc: 0.7500\n",
      "Epoch 149/150\n",
      "12/12 [==============================] - 0s 167us/step - loss: 0.2121 - acc: 0.7500\n",
      "Epoch 150/150\n",
      "12/12 [==============================] - 0s 168us/step - loss: 0.2121 - acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1866eb15d30>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='sigmoid'))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])\n",
    "# model.fit(X, y, epochs=150, batch_size=10,validation_split=0.1)\n",
    "model.fit(X_train, y_train, batch_size=12, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 111ms/step\n",
      "0.255665123462677 0.0\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_test, y_test)\n",
    "print (val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17565064085760265\n",
      "0.17014923254724265\n",
      "0.16479356493188366\n",
      "0.15958449036463793\n",
      "0.15452702729588674\n",
      "0.10258752818333748\n",
      "0.1534244015004646\n",
      "0.10345156449615807\n",
      "0.10034553296690578\n",
      "0.09738328505446624\n",
      "0.159690593594443\n",
      "0.15477036180854592\n",
      "0.1500077883825959\n",
      "0.14539643925788734\n",
      "0.14093765870181701\n",
      "0.13663188673451643\n",
      "0.13247874547955574\n",
      "0.1215705793741531\n",
      "0.13224224605959664\n",
      "0.1217639196158044\n",
      "0.11818422398286232\n",
      "0.11475332632366671\n",
      "0.13931581409587482\n",
      "0.1352097836948171\n",
      "0.13125608942839778\n",
      "0.12744536340403903\n",
      "0.12377564478418351\n",
      "0.12024449734489105\n",
      "0.11684908677225453\n",
      "0.136960090061692\n",
      "0.1171712232447138\n",
      "0.13658842017160305\n",
      "0.13276087821676819\n",
      "0.12907516199501104\n",
      "0.12447915109977602\n",
      "0.1210636100552414\n",
      "0.11778307727280146\n",
      "0.11462750179198423\n",
      "0.11159370292046504\n",
      "0.10867830861127\n",
      "0.1058778068467008\n",
      "0.14890104317688696\n",
      "0.1065385224985451\n",
      "0.14810585546787003\n",
      "0.1442029000259248\n",
      "0.14042981839150076\n",
      "0.11375147323244424\n",
      "0.11089239795899934\n",
      "0.10814869751847599\n",
      "0.10551077916674272\n",
      "0.10297530542995126\n",
      "0.10053889622623598\n",
      "0.09819815966834274\n",
      "0.157886445388916\n",
      "0.09905577433868724\n",
      "0.15679626008004074\n",
      "0.15293582246894172\n",
      "0.14919244291501615\n",
      "0.10600515111249022\n",
      "0.10358881192895608\n",
      "0.10126978347587177\n",
      "0.09903936435593401\n",
      "0.09689449624651014\n",
      "0.09483214535919114\n",
      "0.09284932045319978\n",
      "0.1644619388883324\n",
      "0.09381570496911747\n",
      "0.16317904723898674\n",
      "0.15943730793904717\n",
      "0.1558007160845834\n",
      "0.10042402793794959\n",
      "0.09836183220082108\n",
      "0.09638151550294748\n",
      "0.09447535753951249\n",
      "0.09264071264692088\n",
      "0.09087498478110144\n",
      "0.08917563825905166\n",
      "0.16911409815451764\n",
      "0.09019607968725744\n",
      "0.16771559478972534\n",
      "0.16413981319746207\n",
      "0.16065867257348534\n",
      "0.09643393339887908\n",
      "0.0946588393104101\n",
      "0.09295279926718043\n",
      "0.09130902277530788\n",
      "0.08972528240823051\n",
      "0.0881994055775751\n",
      "0.08672928127562886\n",
      "0.17224419505107255\n",
      "0.08776938385106368\n",
      "0.17078682105995166\n",
      "0.16740485564767202\n",
      "0.16410838163275662\n",
      "0.09363169785141569\n",
      "0.0920931468435825\n",
      "0.09061307379916496\n",
      "0.08918552003049131\n",
      "0.08780863478461319\n",
      "0.08648061876196798\n",
      "0.08519972867719215\n",
      "0.1741734102158292\n",
      "0.08623748882821226\n",
      "0.17269843024192855\n",
      "0.16952513545407907\n",
      "0.16642931612123527\n",
      "0.09173114466115621\n",
      "0.09039065202718832\n",
      "0.08909990718158656\n",
      "0.08785367819335883\n",
      "0.08665043685968267\n",
      "0.08548869988031528\n",
      "0.08436703221865778\n",
      "0.17515650129340268\n",
      "0.08538814253773165\n",
      "0.17369363486034525\n",
      "0.1707350357631772\n",
      "0.1678467916282036\n",
      "0.09052568814108454\n",
      "0.08935348659603458\n",
      "0.08822379245907434\n",
      "0.08713200336099662\n",
      "0.08607686071809613\n",
      "0.08505714364886101\n",
      "0.08407167165877778\n",
      "0.1753956133351577\n",
      "0.08506673213331838\n",
      "0.17396598202329838\n",
      "0.171222014040971\n",
      "0.16854198051248268\n",
      "0.08986326497474557\n",
      "0.08883587803610525\n",
      "0.08784495773701474\n",
      "0.08688644628452645\n",
      "0.08595930776250803\n",
      "0.08506253719737188\n",
      "0.08419516284301419\n",
      "0.17505183585337555\n",
      "0.08515800089841581\n",
      "0.17367012658927325\n",
      "0.17113648081985808\n",
      "0.16866090771194778\n",
      "0.08962965553201672\n",
      "0.08872817934524267\n",
      "0.0878580991372666\n",
      "0.08701582907686158\n",
      "0.08620051602457347\n",
      "0.0854113318713066\n",
      "0.0846474755677339\n",
      "0.17425423936333226\n",
      "0.08557411119689644\n",
      "0.17293029546909436\n",
      "0.17059970813428013\n",
      "0.16832179663220462\n",
      "0.08973733912041\n",
      "0.088946234788801\n",
      "0.08818224580570357\n",
      "0.08744219675089361\n",
      "0.08672538407825502\n",
      "0.0860311242950448\n",
      "0.08535875581011211\n",
      "0.17310676773586345\n",
      "0.08624674526840716\n",
      "0.1718467739379034\n",
      "0.1697099630099899\n",
      "0.16762083778463846\n",
      "0.09011797249143381\n",
      "0.08942421785885447\n",
      "0.08875394631782253\n",
      "0.08810434071670527\n",
      "0.08747481979895315\n",
      "0.08686481826663929\n",
      "0.08627378848523122\n",
      "0.17169347062380305\n",
      "0.08712179321946634\n",
      "0.1705008499492918\n",
      "0.16854721823474353\n",
      "0.1666366541328092\n",
      "0.09071724842825808\n",
      "0.0901097405357839\n",
      "0.08952261957336148\n",
      "0.08895338234779769\n",
      "0.08840154755633385\n",
      "0.08786664653519882\n",
      "0.08734822484002756\n",
      "0.17008249931150152\n",
      "0.08815571699848747\n",
      "0.1689586022033722\n",
      "0.16717677676291628\n",
      "0.16543375214938824\n",
      "0.09149133072374736\n",
      "0.09096046239988327\n",
      "0.09044733109752183\n",
      "0.08994970974382978\n",
      "0.08946719877518809\n",
      "0.088999408602364\n",
      "0.08854596107659134\n",
      "0.16832919306523367\n",
      "0.08931301403477941\n",
      "0.16727383286247302\n",
      "0.1656520825405238\n",
      "0.1640652037229813\n",
      "0.09240434425464274\n",
      "0.0919417014769176\n",
      "0.09149451946999676\n",
      "0.09106081479037466\n",
      "0.09064025478421948\n",
      "0.09023251464813654\n",
      "0.08983727878686683\n",
      "0.16647849526988032\n",
      "0.09056441249104814\n",
      "0.16549036693131453\n",
      "0.16401692428435613\n",
      "0.16257474973127084\n",
      "0.0934265794670102\n",
      "0.09302472243707587\n",
      "0.09263636439353058\n",
      "0.09225973746514156\n",
      "0.09189456384423501\n",
      "0.09154057188909422\n",
      "0.09119749737771878\n",
      "0.16456687008166518\n",
      "0.0918855606501577\n",
      "0.1636438779551703\n",
      "0.16230718356909749\n",
      "0.1609984678446115\n",
      "0.09453318660078147\n",
      "0.09418548886386413\n",
      "0.09384959415097076\n",
      "0.09352392580421653\n",
      "0.0932082510508307\n",
      "0.0929023419530481\n",
      "0.09260597656207988\n",
      "0.1626238404565257\n",
      "0.09325605563234263\n",
      "0.1617633538517562\n",
      "0.16055223662921841\n",
      "0.15936610902674636\n",
      "0.09570321010146988\n",
      "0.09540373798135908\n",
      "0.09511459850499325\n",
      "0.09483438497427706\n",
      "0.09456290167086691\n",
      "0.0942999566628084\n",
      "0.0940453628630787\n",
      "0.16067323352158122\n",
      "0.09465870947867462\n",
      "0.15987228431403988\n",
      "0.1587760888760759\n",
      "0.15770217882392862\n",
      "0.0969188627349686\n",
      "0.09666228288430793\n",
      "0.09641475741304613\n",
      "0.0961750309555227\n",
      "0.09594293835366585\n",
      "0.09571831741148329\n",
      "0.09550100986289668\n",
      "0.15873419537966524\n",
      "0.09607898466574748\n",
      "0.15798962886070547\n",
      "0.15699829968054524\n",
      "0.15602681909074037\n",
      "0.0981649712236045\n",
      "0.09794647792718292\n",
      "0.09773592490907292\n",
      "0.09753219174530518\n",
      "0.09733513854970548\n",
      "0.09714462775139941\n",
      "0.09696052497699227\n",
      "0.1568220212562683\n",
      "0.09750455315900332\n",
      "0.1561306093272465\n",
      "0.15523474005371657\n",
      "0.15435653135057545\n",
      "0.09942854662282052\n",
      "0.09924380314195198\n",
      "0.09906602657224974\n",
      "0.09889421695825808\n",
      "0.09872825537509423\n",
      "0.0985680247065102\n",
      "0.09841341044670406\n",
      "0.15494883590718864\n",
      "0.09892494745841933\n",
      "0.15430736012865262\n",
      "0.1534982155163128\n",
      "0.15270477285670594\n",
      "0.10069844691181536\n",
      "0.10054353697500351\n",
      "0.10039474162048669\n",
      "0.10025116854237702\n",
      "0.10011271625918038\n",
      "0.0999792847017174\n",
      "0.09985077593997053\n",
      "0.15312415161998397\n",
      "0.10033128147762553\n",
      "0.15252946236060444\n",
      "0.15179897921830857\n",
      "0.151082449296912\n",
      "0.10196510881542582\n",
      "0.10183649559587125\n",
      "0.10171324906777908\n",
      "0.10159457319100751\n",
      "0.1014803810521785\n",
      "0.10137058684066112\n",
      "0.10126510650586178\n",
      "0.15135532574980343\n",
      "0.101716025290916\n",
      "0.15080438262291024\n",
      "0.15014515521367347\n",
      "0.14949832300707963\n",
      "0.10322033230963708\n",
      "0.103114823062967\n",
      "0.10301402302882083\n",
      "0.1029172223003531\n",
      "0.10282434617803897\n",
      "0.10273532082363486\n",
      "0.10265007385323255\n",
      "0.1496479357369461\n",
      "0.10307282192589523\n",
      "0.14913783360754493\n",
      "0.1485430880016103\n",
      "0.14795935184901476\n",
      "0.10445710564870976\n",
      "0.1043718207419168\n",
      "0.10429066609921826\n",
      "0.10421300891072822\n",
      "0.104138784759\n",
      "0.10406792989978948\n",
      "0.10400038179603201\n",
      "0.14800608645966457\n",
      "0.10439633721294149\n",
      "0.14753407052284345\n",
      "0.14699763154852966\n",
      "0.14647097110656124\n",
      "0.10566946178974557\n",
      "0.1056018072243881\n",
      "0.10553777241303319\n",
      "0.10547679357043256\n",
      "0.10541881497214732\n",
      "0.10536378142065661\n",
      "0.10531163872520004\n",
      "0.14643266227763327\n",
      "0.10568213570163654\n",
      "0.14599613503513525\n",
      "0.14551238870809227\n",
      "0.1450373285630682\n",
      "0.10685235924321461\n",
      "0.10680000202472677\n",
      "0.10675081389009063\n",
      "0.10670429285728174\n",
      "0.10666039058391602\n",
      "0.10661905914091195\n",
      "0.10658025144288907\n",
      "0.14492953404091075\n",
      "0.10692657711983637\n",
      "0.14452605642665947\n",
      "0.14408991007780528\n",
      "0.14366148115385408\n",
      "0.10800158194747465\n",
      "0.1079624278204394\n",
      "0.10792604459655235\n",
      "0.10789198562910157\n",
      "0.10786020887265411\n",
      "0.10783067260695804\n",
      "0.10780333582231298\n",
      "0.143497729574011\n",
      "0.1081267289702486\n",
      "0.1431250179934511\n",
      "0.14273185976056893\n",
      "0.1423455601239066\n",
      "0.10911365394597201\n",
      "0.10908582713079702\n",
      "0.10906041922027938\n",
      "0.10903703310428932\n",
      "0.10901563213280925\n",
      "0.10899617991273951\n",
      "0.1089786406523691\n",
      "0.1421375746364029\n",
      "0.10928029174604469\n",
      "0.1417934952804429\n",
      "0.1414391541730003\n",
      "0.14109091039352997\n",
      "0.11018576556079031\n",
      "0.11016759020891402\n",
      "0.11015152251127107\n",
      "0.11013720969141999\n",
      "0.11012461974260594\n",
      "0.11011372086216341\n",
      "0.11010448175892845\n",
      "0.14084881007385855\n",
      "0.11038553396895819\n",
      "0.14053137153733128\n",
      "0.14021207891909865\n",
      "0.13989820879975232\n",
      "0.11121570848253741\n",
      "0.1112056916268948\n",
      "0.1111975072207916\n",
      "0.11119084215034386\n",
      "0.1111856684216621\n",
      "0.111181958204088\n",
      "0.11117968410409979\n",
      "0.13963068978502455\n",
      "0.11144123485045805\n",
      "0.13933803475290207\n",
      "0.139050387800784\n",
      "0.13876756501059834\n",
      "0.11220181778219111\n",
      "0.11219863360455977\n",
      "0.11219703862990509\n",
      "0.11219675521133028\n",
      "0.11219775883685472\n",
      "0.11220002512612924\n",
      "0.11220353007411014\n",
      "0.1384820632141299\n",
      "0.11244663287277605\n",
      "0.13821245976723476\n",
      "0.1379533872452017\n",
      "0.1376986081817981\n",
      "0.11314291932573295\n",
      "0.11314539459728927\n",
      "0.11314924421370359\n",
      "0.11315422222557107\n",
      "0.11316030715328712\n",
      "0.11316747762442021\n",
      "0.11317571259016207\n",
      "0.13740144532482731\n",
      "0.11340137899697901\n",
      "0.13715327825183612\n",
      "0.1369200087741944\n",
      "0.13669056182364003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11403828145715737\n",
      "0.11404538203587931\n",
      "0.1140536673580586\n",
      "0.11406291978463486\n",
      "0.11407312048572654\n",
      "0.11408425071965907\n",
      "0.11409629202494422\n",
      "0.1363870763928988\n",
      "0.114305493540729\n",
      "0.13615883876900597\n",
      "0.13594887160680977\n",
      "0.13574230885343355\n",
      "0.11488757012399381\n",
      "0.11489838841419014\n",
      "0.11491022434344829\n",
      "0.11492288553948665\n",
      "0.11493635549463345\n",
      "0.11495061777466903\n",
      "0.11496565618884698\n",
      "0.13543697345816574\n",
      "0.11515932603783495\n",
      "0.1352272586556635\n",
      "0.13503833705455073\n",
      "0.13485244841125052\n",
      "0.11569080686302162\n",
      "0.11570455015938468\n",
      "0.11571916404534739\n",
      "0.1157344786809431\n",
      "0.11575047959885594\n",
      "0.11576715239368585\n",
      "0.11578448287230064\n",
      "0.13454897488020737\n",
      "0.11596351760340108\n",
      "0.1343564691061416\n",
      "0.13418655602541119\n",
      "0.13401934569880217\n",
      "0.11644832925196576\n",
      "0.11646430890397476\n",
      "0.11648102998176425\n",
      "0.11649834272156513\n",
      "0.11651623445256158\n",
      "0.11653469255676947\n",
      "0.11655370460179852\n",
      "0.13372077913131067\n",
      "0.11671896549028847\n",
      "0.13354425453690472\n",
      "0.1333915106817897\n",
      "0.13324117585004916\n",
      "0.1171607535743145\n",
      "0.11717837491718662\n",
      "0.1171966244740838\n",
      "0.11721537035215747\n",
      "0.11723460146503227\n",
      "0.117254306771944\n",
      "0.11727447539479631\n",
      "0.13294997871786723\n",
      "0.1174267896424692\n",
      "0.1327882870890951\n",
      "0.13265105108570993\n",
      "0.13251596264519905\n",
      "0.11782893954693037\n",
      "0.11784769255318632\n",
      "0.11786697478518991\n",
      "0.11788667024191231\n",
      "0.1179067692361264\n",
      "0.11792726212040926\n",
      "0.11794813939019759\n",
      "0.13223408993451316\n",
      "0.11808830113602455\n",
      "0.13208615694936654\n",
      "0.13196292750060273\n",
      "0.13184161272637668\n",
      "0.11845395703114202\n",
      "0.11847340764270005\n",
      "0.11849330116605426\n",
      "0.11851353571690809\n",
      "0.11853410284457006\n",
      "0.11855499413341514\n",
      "0.11857620129347894\n",
      "0.13157057901192704\n",
      "0.11870497245583915\n",
      "0.13143539903462595\n",
      "0.13132481889213496\n",
      "0.13121594585422722\n",
      "0.11903705469404764\n",
      "0.11905683679899955\n",
      "0.1190769867850268\n",
      "0.11909741529353905\n",
      "0.11911811496710928\n",
      "0.11913907847944977\n",
      "0.11916029861493112\n",
      "0.1309568851096125\n",
      "0.11927840959156531\n",
      "0.13083351648294422\n",
      "0.13073435807281747\n",
      "0.13063672165236212\n",
      "0.1195796306135734\n",
      "0.11959943863480865\n",
      "0.11961954953860011\n",
      "0.11963988506710273\n",
      "0.11966043882949152\n",
      "0.11968120446276759\n",
      "0.11970217570145049\n",
      "0.13039044052125948\n",
      "0.11981032595547765\n",
      "0.130278001313606\n",
      "0.1301891538595977\n",
      "0.1301016632146676\n",
      "0.12008320483332467\n",
      "0.12010278689826243\n",
      "0.12012261575322332\n",
      "0.1201426229659615\n",
      "0.12016280299994771\n",
      "0.12018315034363342\n",
      "0.12020365957143812\n",
      "0.12986868839612994\n",
      "0.1203025181318474\n",
      "0.12976635255821464\n",
      "0.12968681055496686\n",
      "0.12960847789413352\n",
      "0.12054939387550284\n",
      "0.12056854553762748\n",
      "0.12058789578879407\n",
      "0.1206073848823301\n",
      "0.12062700803618621\n",
      "0.12064676049080904\n",
      "0.12066663756242674\n",
      "0.12938909823048564\n",
      "0.12075684346607136\n",
      "0.129296092117424\n",
      "0.12922494501614598\n",
      "0.12915487554725294\n",
      "0.12097988721540955\n",
      "0.12099844569929814\n",
      "0.12101716154891463\n",
      "0.12103598268495601\n",
      "0.12105490499097364\n",
      "0.12107392437080915\n",
      "0.12109303679507916\n",
      "0.1289491793446598\n",
      "0.12117519949485932\n",
      "0.128864778560811\n",
      "0.1288012015405159\n",
      "0.12873858447229575\n",
      "0.12137642571189498\n",
      "0.12139426465412749\n",
      "0.12141222589334255\n",
      "0.1214302641091835\n",
      "0.12144837577155193\n",
      "0.12146655736865658\n",
      "0.12148480544750016\n",
      "0.12854649253123981\n",
      "0.12155950520851672\n",
      "0.1284700190580943\n",
      "0.1284132647662937\n",
      "0.12835736525077385\n",
      "0.12174078197644984\n",
      "0.12175780663533399\n",
      "0.12177492393615334\n",
      "0.12179209450794255\n",
      "0.1218093153362277\n",
      "0.12182658342303877\n",
      "0.12184389582211642\n",
      "0.12817866003592338\n",
      "0.12191168412439118\n",
      "0.12810947960647362\n",
      "0.12805887076383365\n",
      "0.1280090226776236\n",
      "0.12207474265093327\n",
      "0.12209088555843951\n",
      "0.12210709620031922\n",
      "0.12212334043442345\n",
      "0.1221396156987584\n",
      "0.12215591944618125\n",
      "0.12217224917496579\n",
      "0.12784337401350115\n",
      "0.1222336491380594\n",
      "0.12778089369996065\n",
      "0.12773581647360668\n",
      "0.12769141594592165\n",
      "0.1223800925511593\n",
      "0.12239530958090361\n",
      "0.12241057358664736\n",
      "0.12242585501449939\n",
      "0.12244115169857266\n",
      "0.12245646148630711\n",
      "0.12247178226496265\n",
      "0.1275384035860117\n",
      "0.12252728910662906\n",
      "0.12748206957122174\n",
      "0.1274419676309939\n",
      "0.1274024672355065\n",
      "0.12265860062142914\n",
      "0.1226728674470064\n",
      "0.12268716410295816\n",
      "0.12270146505498558\n",
      "0.12271576848300204\n",
      "0.12273007257883893\n",
      "0.12274437556916924\n",
      "0.12726160061765862\n",
      "0.12279445710715357\n",
      "0.12721089612393066\n",
      "0.12717526530486611\n",
      "0.1271401688411104\n",
      "0.12291200763402228\n",
      "0.12292531655249711\n",
      "0.12293864128842064\n",
      "0.12295195982295154\n",
      "0.12296527063695058\n",
      "0.12297857222189096\n",
      "0.12299186309966086\n",
      "0.12701090431098594\n",
      "0.12303696030294381\n",
      "0.12696534766340806\n",
      "0.12693373116601883\n",
      "0.12690258896405607\n",
      "0.12314201555790423\n",
      "0.12315437265382805\n",
      "0.12316673425833934\n",
      "0.12317908142178167\n",
      "0.12319141288602069\n",
      "0.12320372740232564\n",
      "0.12321602374844676\n",
      "0.1267843447206445\n",
      "0.1232565513416967\n",
      "0.12674348752498513\n",
      "0.12671547159250088\n",
      "0.1266878762818899\n",
      "0.12335027851261655\n",
      "0.12336170113855842\n",
      "0.12337311928652865\n",
      "0.12338451668160698\n",
      "0.1233958922911515\n",
      "0.12340724509080635\n",
      "0.1234185740792035\n",
      "0.12658004527448546\n",
      "0.1234549212019349\n",
      "0.126543470692734\n",
      "0.12651868071140512\n",
      "0.1264942634022061\n",
      "0.12353839521651815\n",
      "0.1235489097667744\n",
      "0.12355941283574447\n",
      "0.12356989047515503\n",
      "0.12358034184634407\n",
      "0.1235907661179055\n",
      "0.12360116247832355\n",
      "0.12639622438639844\n",
      "0.12363369339829113\n",
      "0.12636354549567136\n",
      "0.1263416424705009\n",
      "0.12632006930010126\n",
      "0.12370790283324906\n",
      "0.12371754278813252\n",
      "0.12372716594147093\n",
      "0.12373676036496646\n",
      "0.1237463253860378\n",
      "0.1237558603384137\n",
      "0.12376536457297059\n",
      "0.12623119624100648\n",
      "0.12379441945163877\n",
      "0.12620205446401278\n",
      "0.12618273182793552\n",
      "0.12616370083295833\n",
      "0.12386027211643397\n",
      "0.12386907633533135\n",
      "0.12387785985061933\n",
      "0.12388661248425638\n",
      "0.12389533370510679\n",
      "0.12390402298747975\n",
      "0.12391267982040917\n",
      "0.12608337082680904\n",
      "0.12393857552693337\n",
      "0.1260574344243036\n",
      "0.12604041514390169\n",
      "0.12602365342135863\n",
      "0.1239969037501751\n",
      "0.12400491499239451\n",
      "0.12401290281432681\n",
      "0.12402085855138906\n",
      "0.12402878179220239\n",
      "0.12403667213004545\n",
      "0.12404452917078616\n",
      "0.12595125329141618\n",
      "0.12406756013979775\n",
      "0.12592821590907663\n",
      "0.12591324985444416\n",
      "0.12589851098068267\n",
      "0.1241191257817043\n",
      "0.12412638943501304\n",
      "0.12413362793295772\n",
      "0.1241408339169016\n",
      "0.12414800707619117\n",
      "0.12415514710411783\n",
      "0.12416225370468476\n",
      "0.12583344268996058\n",
      "0.12418269283228801\n",
      "0.1258130219538978\n",
      "0.1257998835042887\n",
      "0.12578694518417705\n",
      "0.12422819204259693\n",
      "0.12423475504026156\n",
      "0.1242412919515143\n",
      "0.12424779654216132\n",
      "0.1242542685856361\n",
      "0.12426070785867527\n",
      "0.12426711414708175\n",
      "0.12572863019543895\n",
      "0.12428521371881744\n",
      "0.12571056635210226\n",
      "0.12569905221255254\n",
      "0.12568771413479832\n",
      "0.124325281456078\n",
      "0.12433119136416498\n",
      "0.1243370749048615\n",
      "0.12434292680997604\n",
      "0.12434874692254068\n",
      "0.1243545350883175\n",
      "0.12436029116069669\n",
      "0.12563559683748252\n",
      "0.12437628380478995\n",
      "0.12561965143505135\n",
      "0.12560957864229935\n",
      "0.12559966051983332\n",
      "0.12441149813008517\n",
      "0.12441680238774684\n",
      "0.12442208051435351\n",
      "0.12442732806968863\n",
      "0.12443254495382326\n",
      "0.12443773106904941\n",
      "0.1244428863240359\n",
      "0.1255532108337753\n",
      "0.12445698598301137\n",
      "0.12553916544324673\n",
      "0.12553036954202046\n",
      "0.12552170931904166\n",
      "0.12448787213877159\n",
      "0.12449261743523209\n",
      "0.12449733724050976\n",
      "0.124502027822371\n",
      "0.1245066891270916\n",
      "0.12451132110271941\n",
      "0.12451592370259391\n",
      "0.12548042457593125\n",
      "0.1245283266162755\n",
      "0.12546807955103015\n",
      "0.12546041292416546\n",
      "0.12545286513376827\n",
      "0.12455536089893184\n",
      "0.12455959267188615\n",
      "0.12456379990021144\n",
      "0.12456797945557069\n",
      "0.12457213132114782\n",
      "0.12457625548150704\n",
      "0.12458035192556645\n",
      "0.125416271329051\n",
      "0.1245912376185752\n",
      "0.1254054446048153\n",
      "0.1253987749427494\n",
      "0.1253922092010705\n",
      "0.12461485105229704\n",
      "0.12461861309344353\n",
      "0.1246223517613703\n",
      "0.12462606444154928\n",
      "0.124629751146144\n",
      "0.12463341188835779\n",
      "0.12463704668494252\n",
      "0.12535986170135935\n",
      "0.1246465789520305\n",
      "0.12535038763180337\n",
      "0.12534459652878335\n",
      "0.1253388961533499\n",
      "0.12466716076965877\n",
      "0.12467049492409017\n",
      "0.12467380703302906\n",
      "0.12467709491796612\n",
      "0.12468035861332576\n",
      "0.12468359815428015\n",
      "0.12468681357886151\n",
      "0.12531037993725797\n",
      "0.1246951414617598\n",
      "0.1253021081729093\n",
      "0.12529708983880244\n",
      "0.1252921505802609\n",
      "0.12471304239823516\n",
      "0.1247159883454103\n",
      "0.12471891367429631\n",
      "0.12472181657538985\n",
      "0.12472469709972572\n",
      "0.12472755529883832\n",
      "0.12473039122653655\n",
      "0.12526708008382498\n",
      "0.12473764997642516\n",
      "0.1252598744901738\n",
      "0.12525553456808855\n",
      "0.12525126344578055\n",
      "0.1247531853794679\n",
      "0.12475578048447254\n",
      "0.12475835645126444\n",
      "0.12476091178176078\n",
      "0.12476344653889364\n",
      "0.12476596078588648\n",
      "0.12476845458774229\n",
      "0.1252292820772558\n",
      "0.12477476660795211\n",
      "0.12522301969528013\n",
      "0.12521927417633535\n",
      "0.12521558840927555\n",
      "0.1247882193704406\n",
      "0.12479049859520726\n",
      "0.1247927601770223\n",
      "0.12479500287986427\n",
      "0.12479722677466883\n",
      "0.12479943193249075\n",
      "0.12480161842574881\n",
      "0.12519636779202162\n",
      "0.12480709418985952\n",
      "0.12519093784196197\n",
      "0.1251877120695009\n",
      "0.1251845380952454\n",
      "0.12481871750822575\n",
      "0.12482071337332196\n",
      "0.12482269307593802\n",
      "0.12482465559991661\n",
      "0.12482660102101617\n",
      "0.12482852941497319\n",
      "0.1248304408585423\n",
      "0.12516777709164753\n",
      "0.12483517979962906\n",
      "0.12516308002112767\n",
      "0.1251603077774842\n",
      "0.12515758035216226\n",
      "0.12484519976261231\n",
      "0.12484694235111277\n",
      "0.12484867021947042\n",
      "0.1248503825354161\n",
      "0.1248520793769654\n",
      "0.12485376082199949\n",
      "0.1248554269491318\n",
      "0.125143003916043\n",
      "0.12485951831652324\n",
      "0.12513895049348406\n",
      "0.12513657316309465\n",
      "0.12513423453654066\n",
      "0.12486813632875225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12486965332457871\n",
      "0.12487115698677859\n",
      "0.1248726466363837\n",
      "0.12487412235163059\n",
      "0.1248755842105335\n",
      "0.12487703229160525\n",
      "0.1251215924363029\n",
      "0.12488055597212405\n",
      "0.12511810289036882\n",
      "0.12511606869360506\n",
      "0.12511406785409024\n",
      "0.12488795101720822\n",
      "0.12488926777115343\n",
      "0.12489057250926576\n",
      "0.1248918646799488\n",
      "0.12489314436007477\n",
      "0.12489441162622765\n",
      "0.12489566655530121\n",
      "0.1251031333038917\n",
      "0.12489869385656811\n",
      "0.12510013650946036\n",
      "0.1250983998020435\n",
      "0.12509669178558\n",
      "0.12490502460463664\n",
      "0.12490616422206985\n",
      "0.12490729306385241\n",
      "0.12490841068384385\n",
      "0.12490951715635014\n",
      "0.12491061255534076\n",
      "0.1249116969549444\n",
      "0.1250872600171833\n",
      "0.12491429134890565\n",
      "0.1250846927280576\n",
      "0.12508321336133663\n",
      "0.12508175862092913\n",
      "0.12491969811382002\n",
      "0.12492068155881135\n",
      "0.12492165538516126\n",
      "0.12492261923371965\n",
      "0.1249235731753448\n",
      "0.12492451728052606\n",
      "0.12492545161979397\n",
      "0.12507364542449853\n",
      "0.12492766944519436\n",
      "0.12507145155279112\n",
      "0.12507019429051566\n",
      "0.12506895812107857\n",
      "0.1249322759969453\n",
      "0.12493312220823542\n",
      "0.12493395987188372\n",
      "0.1249347887002223\n",
      "0.12493560876004745\n",
      "0.1249364201177674\n",
      "0.12493722283974094\n",
      "0.12506199837911772\n",
      "0.12493911396278312\n",
      "0.12506012832094537\n",
      "0.12505906230847308\n",
      "0.12505801432342611\n",
      "0.12494302920086352\n",
      "0.12494375521574069\n",
      "0.12494447366732936\n",
      "0.12494518432646216\n",
      "0.12494588725547935\n",
      "0.12494658251632478\n",
      "0.12494727017082473\n",
      "0.1250520605582704\n",
      "0.12494887860373895\n",
      "0.12505047056511528\n",
      "0.12504956884725532\n",
      "0.12504868250306797\n",
      "0.12495219809753094\n",
      "0.12495281918026714\n",
      "0.12495343359852805\n",
      "0.12495404117081858\n",
      "0.12495464195480749\n",
      "0.12495523600776742\n",
      "0.12495582338680443\n",
      "0.12504360345486773\n",
      "0.12495718786448634\n",
      "0.12504225504969088\n",
      "0.1250414941336202\n",
      "0.12504074629879963\n",
      "0.12495999526691677\n",
      "0.12496052503894843\n",
      "0.12496104896223452\n",
      "0.12496156689395305\n",
      "0.12496207888702855\n",
      "0.12496258499399725\n",
      "0.12496308526719474\n",
      "0.12503642554775735\n",
      "0.12496423978246061\n",
      "0.12503528498470146\n",
      "0.12503464444459816\n",
      "0.12503401500981967\n",
      "0.12496660812334888\n",
      "0.12496705869287322\n",
      "0.12496750414977058\n",
      "0.12496794438244051\n",
      "0.12496837943910345\n",
      "0.12496880936760422\n",
      "0.12496923421556637\n",
      "0.12503034965357032\n",
      "0.12497020851391329\n",
      "0.12502938741986666\n",
      "0.12502884954009436\n",
      "0.12502832106635706\n",
      "0.12497220137955327\n",
      "0.12497258346864899\n",
      "0.12497296110582828\n",
      "0.12497333420456752\n",
      "0.12497370280850911\n",
      "0.12497406696093698\n",
      "0.12497442670490283\n",
      "0.1250252204608067\n",
      "0.12497524673995407\n",
      "0.125024410819306\n",
      "0.125023960273158\n",
      "0.12502351767501893\n",
      "0.12497691934554571\n",
      "0.12497724241331236\n",
      "0.12497756161916225\n",
      "0.12497787689660249\n",
      "0.12497818828488756\n",
      "0.12497849582293435\n",
      "0.12497879954942387\n",
      "0.1250209022446693\n",
      "0.12497948790048309\n",
      "0.12502022281525266\n",
      "0.1250198463764305\n",
      "0.12501947663753052\n",
      "0.12498088806204395\n",
      "0.12498116042259884\n",
      "0.12498142944552093\n",
      "0.12498169508022118\n",
      "0.12498195736180319\n",
      "0.12498221632505462\n",
      "0.1249824720045302\n",
      "0.12501727675931187\n",
      "0.1249830482578666\n",
      "0.12501670813730642\n",
      "0.12501639442146031\n",
      "0.1250160863397099\n",
      "0.12498421727021954\n",
      "0.12498444620469161\n",
      "0.12498467226523007\n",
      "0.12498489541379222\n",
      "0.12498511568159758\n",
      "0.12498533309957233\n",
      "0.12498554769841767\n",
      "0.12501424130260336\n",
      "0.12498602879405779\n",
      "0.1250137667122255\n",
      "0.12501350594603783\n",
      "0.12501324990597568\n",
      "0.12498700222141262\n",
      "0.12498719408332898\n",
      "0.12498738347956667\n",
      "0.12498757038190968\n",
      "0.12498775481797808\n",
      "0.12498793681512232\n",
      "0.12498811640047848\n",
      "0.12501170694721647\n",
      "0.12498851694639407\n",
      "0.1250113119279969\n",
      "0.12501109574343344\n",
      "0.12501088351341366\n",
      "0.12498932533191116\n",
      "0.12498948564559777\n",
      "0.12498964385146309\n",
      "0.12498979992892707\n",
      "0.12498995390230334\n",
      "0.12499010579565922\n",
      "0.12499025563286076\n",
      "0.12500959693081734\n",
      "0.12499058818851934\n",
      "0.12500926905491982\n",
      "0.12500909030641366\n",
      "0.12500891485841903\n",
      "0.12499125768907744\n",
      "0.12499139124087909\n",
      "0.12499152299719558\n",
      "0.12499165294332815\n",
      "0.12499178110057647\n",
      "0.12499190749001743\n",
      "0.12499203213254066\n",
      "0.1250078451973313\n",
      "0.1249923074638258\n",
      "0.12500757381566355\n",
      "0.12500742641813758\n",
      "0.12500728176814865\n",
      "0.12499286041601465\n",
      "0.12499297133829697\n",
      "0.1249930807365573\n",
      "0.12499318860058085\n",
      "0.1249932949489405\n",
      "0.12499339980000805\n",
      "0.12499350317198354\n",
      "0.1250063950806881\n",
      "0.12499373047950656\n",
      "0.125006171095712\n",
      "0.1250060498814795\n",
      "0.12500593094846596\n",
      "0.12499418590262897"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Documents\\ML\\Tubes2\\MachineLearning-Tubes2\\nn.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.1249942777506516\n",
      "0.12499436830962217\n",
      "0.1249944575727049\n",
      "0.12499454555602156\n",
      "0.12499463227551404\n",
      "0.12499471774696767\n",
      "0.12500519812206748\n",
      "0.12499490486977588\n",
      "0.12500501378525028\n",
      "0.12500491437796454\n",
      "0.1250048168596929\n",
      "0.12499527891138867\n",
      "0.12499535473324057\n",
      "0.12499542946860219\n",
      "0.12499550311314882\n",
      "0.12499557568081303\n",
      "0.12499564718536732\n",
      "0.12499571764044265\n",
      "0.12500421301146705\n",
      "0.1249958712370962\n",
      "0.1250040617433628\n",
      "0.12500398044731661\n",
      "0.1250039007112968\n",
      "0.12499617756633728\n",
      "0.12499623996620418\n",
      "0.12499630145350966\n",
      "0.12499636202576454\n",
      "0.12499642169495744\n",
      "0.12499648047293527\n",
      "0.12499653837141843\n",
      "0.12500340464436469\n",
      "0.12499666408034703\n",
      "0.12500328087538426\n",
      "0.12500321457858463\n",
      "0.1250031495666006\n",
      "0.12499691423400748\n",
      "0.12499696542910005\n",
      "0.12499701586038815\n",
      "0.12499706552669626\n",
      "0.12499711443829686\n",
      "0.12499716260533782\n",
      "0.12499721003785373\n",
      "0.12500274328433456\n",
      "0.12499731261883923\n",
      "0.12500264231434113\n",
      "0.1250025884039055\n",
      "0.1250025355486958\n",
      "0.12499751630483182\n",
      "0.12499755817634524\n",
      "0.12499759941078831\n",
      "0.12499764000790027\n",
      "0.12499767997644674\n",
      "0.12499771932508373\n",
      "0.12499775806236729\n",
      "0.12500220382267252\n",
      "0.12499784152090959\n",
      "0.1250021216976296\n",
      "0.12500207798616714\n",
      "0.12500203513893496\n",
      "0.1249980068834795\n",
      "0.12499804102198427\n",
      "0.12499807463097425\n",
      "0.12499810771080287\n",
      "0.12499814026891905\n",
      "0.12499817231267607\n",
      "0.12499820384933959\n",
      "0.1250017651263744\n",
      "0.12499827154557391\n",
      "0.12500169853037196\n",
      "0.1250016631921254\n",
      "0.12500162855967\n",
      "0.12499840539628777\n",
      "0.12499843314196263\n",
      "0.12499846044905326\n",
      "0.12499848731830315\n",
      "0.12499851375601662\n",
      "0.12499853976841518\n",
      "0.12499856536164346\n",
      "0.12500140946617597\n",
      "0.12499862010537567\n",
      "0.1250013556272634\n",
      "0.12500132714289275\n",
      "0.12500129923325923\n",
      "0.12499872812361763\n",
      "0.12499875060174404\n",
      "0.12499877271786942\n",
      "0.1249987944729632\n",
      "0.12499881587233959\n",
      "0.1249988369212412\n",
      "0.12499885762484418\n",
      "0.12500112201677707\n",
      "0.12499890175816812\n",
      "0.1250010786251379\n",
      "0.12500105573413126\n",
      "0.1250010333097751\n",
      "0.12499898866457143\n",
      "0.12499900681670278\n",
      "0.12499902467108866\n",
      "0.12499904222880677\n",
      "0.12499905949431883\n",
      "0.1249990764720252\n",
      "0.12499909316626862\n",
      "0.12500089042183665\n",
      "0.12499912863512334\n",
      "0.12500085555894752\n",
      "0.12500083721873798\n",
      "0.12500081925629813\n",
      "0.12499919834107294\n",
      "0.12499921295228182\n",
      "0.12499922731945444\n",
      "0.12499924144369425\n",
      "0.12499925532873261\n",
      "0.12499926897824826\n",
      "0.12499928239587056\n",
      "0.12500070441680516\n",
      "0.1249993108117902\n",
      "0.1250006764943312\n",
      "0.12500066184529057\n",
      "0.12500064750115072\n",
      "0.12499936654785078\n",
      "0.1249993782704422\n"
     ]
    }
   ],
   "source": [
    "# Classifier by Python (nn)\n",
    "\n",
    "from nn import NeuralNetwork\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "X = np.array([[0, 81, 75, 0],\n",
    "       [0, 64, 65, 1],\n",
    "       [2, 69, 70, 0],\n",
    "       [0, 83, 86, 0],\n",
    "       [2, 75, 70, 1],\n",
    "       [1, 65, 70, 1],\n",
    "       [0, 72, 90, 1],\n",
    "       [1, 71, 91, 1],\n",
    "       [2, 80, 90, 1],\n",
    "       [2, 85, 85, 0],\n",
    "       [1, 68, 80, 0],\n",
    "       [1, 75, 80, 0]])\n",
    "y = np.array([[1], [1], [1], [1], [1], [0], [1], [0], [0], [0], [1], [1]])\n",
    "\n",
    "nn = NeuralNetwork(X,y)\n",
    "nn.add(7)\n",
    "nn.add(5)\n",
    "nn.add(6)\n",
    "nn.add(2)\n",
    "nn.add(3)\n",
    "\n",
    "nn.fit(12,150,0.5,0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
