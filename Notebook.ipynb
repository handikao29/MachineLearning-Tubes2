{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(b'sunny', 85., 85., b'FALSE', b'no')\n",
      " (b'sunny', 80., 90., b'TRUE', b'no')\n",
      " (b'overcast', 83., 86., b'FALSE', b'yes')\n",
      " (b'rainy', 70., 96., b'FALSE', b'yes')\n",
      " (b'rainy', 68., 80., b'FALSE', b'yes')\n",
      " (b'rainy', 65., 70., b'TRUE', b'no')\n",
      " (b'overcast', 64., 65., b'TRUE', b'yes')\n",
      " (b'sunny', 72., 95., b'FALSE', b'no')\n",
      " (b'sunny', 69., 70., b'FALSE', b'yes')\n",
      " (b'rainy', 75., 80., b'FALSE', b'yes')\n",
      " (b'sunny', 75., 70., b'TRUE', b'yes')\n",
      " (b'overcast', 72., 90., b'TRUE', b'yes')\n",
      " (b'overcast', 81., 75., b'FALSE', b'yes')\n",
      " (b'rainy', 71., 91., b'TRUE', b'no')]\n",
      "Dataset: weather\n",
      "\toutlook's type is nominal, range is ('sunny', 'overcast', 'rainy')\n",
      "\ttemperature's type is numeric\n",
      "\thumidity's type is numeric\n",
      "\twindy's type is nominal, range is ('TRUE', 'FALSE')\n",
      "\tplay's type is nominal, range is ('yes', 'no')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from scipy.io import arff\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Read the train dataset from csv file\n",
    "data, meta = arff.loadarff(\"weather.arff\")\n",
    "print(data)\n",
    "print(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 85 85 False]\n",
      " [2 80 90 True]\n",
      " [0 83 86 False]\n",
      " [1 70 96 False]\n",
      " [1 68 80 False]\n",
      " [1 65 70 True]\n",
      " [0 64 65 True]\n",
      " [2 72 95 False]\n",
      " [2 69 70 False]\n",
      " [1 75 80 False]\n",
      " [2 75 70 True]\n",
      " [0 72 90 True]\n",
      " [0 81 75 False]\n",
      " [1 71 91 True]]\n",
      "[0 0 1 1 1 0 1 0 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train_csv = pd.read_csv(\"weather.csv\",header=0)\n",
    "array = np.array(train_csv)\n",
    "X = array[:,:-1]\n",
    "le = LabelEncoder()\n",
    "A = le.fit_transform(X[:,0])\n",
    "y = le.fit_transform(array[:,-1])\n",
    "for i in range(0,len(X)):\n",
    "    X[i,0] = A[i]\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12 samples, validate on 2 samples\n",
      "Epoch 1/150\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 6.3932 - val_loss: 5.2076\n",
      "Epoch 2/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.3427 - val_loss: 5.9661\n",
      "Epoch 3/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.7810 - val_loss: 5.2378\n",
      "Epoch 4/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.1874 - val_loss: 5.3250\n",
      "Epoch 5/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.1117 - val_loss: 5.0781\n",
      "Epoch 6/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.2637 - val_loss: 5.1238\n",
      "Epoch 7/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.1159 - val_loss: 4.5286\n",
      "Epoch 8/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.3592 - val_loss: 4.4149\n",
      "Epoch 9/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.8831 - val_loss: 4.6781\n",
      "Epoch 10/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.9349 - val_loss: 4.4716\n",
      "Epoch 11/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.9700 - val_loss: 4.4292\n",
      "Epoch 12/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.0957 - val_loss: 4.4148\n",
      "Epoch 13/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.0061 - val_loss: 4.5163\n",
      "Epoch 14/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.2446 - val_loss: 4.4079\n",
      "Epoch 15/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.9722 - val_loss: 4.4291\n",
      "Epoch 16/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.2225 - val_loss: 4.4648\n",
      "Epoch 17/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.2621 - val_loss: 4.4060\n",
      "Epoch 18/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.8578 - val_loss: 5.1523\n",
      "Epoch 19/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.3012 - val_loss: 5.2529\n",
      "Epoch 20/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.1909 - val_loss: 4.4215\n",
      "Epoch 21/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.9259 - val_loss: 4.8606\n",
      "Epoch 22/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.1096 - val_loss: 4.9699\n",
      "Epoch 23/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.0929 - val_loss: 4.3961\n",
      "Epoch 24/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.9032 - val_loss: 4.3929\n",
      "Epoch 25/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.8490 - val_loss: 5.0551\n",
      "Epoch 26/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.2325 - val_loss: 5.0651\n",
      "Epoch 27/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.1015 - val_loss: 4.4180\n",
      "Epoch 28/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.9189 - val_loss: 4.9901\n",
      "Epoch 29/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.2219 - val_loss: 5.3657\n",
      "Epoch 30/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.2470 - val_loss: 4.4091\n",
      "Epoch 31/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.0341 - val_loss: 4.3734\n",
      "Epoch 32/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.2630 - val_loss: 5.4448\n",
      "Epoch 33/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.2487 - val_loss: 5.2077\n",
      "Epoch 34/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.1496 - val_loss: 4.3900\n",
      "Epoch 35/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.8806 - val_loss: 4.8617\n",
      "Epoch 36/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.1619 - val_loss: 5.4229\n",
      "Epoch 37/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.4277 - val_loss: 4.8177\n",
      "Epoch 38/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.9528 - val_loss: 4.3470\n",
      "Epoch 39/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.8416 - val_loss: 4.5682\n",
      "Epoch 40/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.2070 - val_loss: 4.7860\n",
      "Epoch 41/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.9584 - val_loss: 4.3503\n",
      "Epoch 42/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.7688 - val_loss: 4.8483\n",
      "Epoch 43/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.0072 - val_loss: 4.5747\n",
      "Epoch 44/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.4593 - val_loss: 4.3504\n",
      "Epoch 45/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.8147 - val_loss: 5.0766\n",
      "Epoch 46/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.9928 - val_loss: 5.9150\n",
      "Epoch 47/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 7.0283 - val_loss: 4.3918\n",
      "Epoch 48/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.8129 - val_loss: 4.7076\n",
      "Epoch 49/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.0267 - val_loss: 4.8862\n",
      "Epoch 50/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.0078 - val_loss: 4.3583\n",
      "Epoch 51/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.7968 - val_loss: 4.6516\n",
      "Epoch 52/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.8324 - val_loss: 4.6235\n",
      "Epoch 53/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.5338 - val_loss: 4.4284\n",
      "Epoch 54/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.0254 - val_loss: 4.7780\n",
      "Epoch 55/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.8944 - val_loss: 4.3715\n",
      "Epoch 56/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.8610 - val_loss: 6.1377\n",
      "Epoch 57/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.7078 - val_loss: 4.3981\n",
      "Epoch 58/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.8605 - val_loss: 5.3868\n",
      "Epoch 59/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.1489 - val_loss: 5.7432\n",
      "Epoch 60/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 6.7202 - val_loss: 4.3874\n",
      "Epoch 61/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.8166 - val_loss: 5.4887\n",
      "Epoch 62/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.4305 - val_loss: 4.8561\n",
      "Epoch 63/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.0745 - val_loss: 5.2995\n",
      "Epoch 64/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.3333 - val_loss: 5.0940\n",
      "Epoch 65/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.2009 - val_loss: 5.1834\n",
      "Epoch 66/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.0704 - val_loss: 4.5583\n",
      "Epoch 67/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.0773 - val_loss: 5.1126\n",
      "Epoch 68/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.2200 - val_loss: 5.2231\n",
      "Epoch 69/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.2856 - val_loss: 5.2392\n",
      "Epoch 70/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.0508 - val_loss: 5.5287\n",
      "Epoch 71/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 6.2005 - val_loss: 5.1932\n",
      "Epoch 72/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.0826 - val_loss: 4.5435\n",
      "Epoch 73/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.7854 - val_loss: 5.5657\n",
      "Epoch 74/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.2722 - val_loss: 5.3669\n",
      "Epoch 75/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.1406 - val_loss: 5.6089\n",
      "Epoch 76/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 7.0173 - val_loss: 5.7310\n",
      "Epoch 77/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.4522 - val_loss: 5.8446\n",
      "Epoch 78/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.6680 - val_loss: 5.1743\n",
      "Epoch 79/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.0866 - val_loss: 4.3451\n",
      "Epoch 80/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.8072 - val_loss: 4.9962\n",
      "Epoch 81/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.2226 - val_loss: 6.0036\n",
      "Epoch 82/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 0us/step - loss: 5.6183 - val_loss: 4.3232\n",
      "Epoch 83/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.7409 - val_loss: 4.5773\n",
      "Epoch 84/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.1611 - val_loss: 4.8952\n",
      "Epoch 85/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.9478 - val_loss: 4.3029\n",
      "Epoch 86/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.8430 - val_loss: 4.5911\n",
      "Epoch 87/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.1800 - val_loss: 4.7664\n",
      "Epoch 88/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.1262 - val_loss: 6.1836\n",
      "Epoch 89/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.7187 - val_loss: 4.3071\n",
      "Epoch 90/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.7313 - val_loss: 4.4856\n",
      "Epoch 91/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.0484 - val_loss: 4.9199\n",
      "Epoch 92/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.0994 - val_loss: 5.6397\n",
      "Epoch 93/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.5133 - val_loss: 5.0265\n",
      "Epoch 94/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.1722 - val_loss: 5.6017\n",
      "Epoch 95/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.4679 - val_loss: 4.9307\n",
      "Epoch 96/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.0937 - val_loss: 5.6037\n",
      "Epoch 97/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.2982 - val_loss: 4.3503\n",
      "Epoch 98/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.3604 - val_loss: 5.4124\n",
      "Epoch 99/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.9841 - val_loss: 5.3176\n",
      "Epoch 100/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.3078 - val_loss: 5.1259\n",
      "Epoch 101/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.1925 - val_loss: 5.2334\n",
      "Epoch 102/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.3116 - val_loss: 5.9702\n",
      "Epoch 103/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.7124 - val_loss: 5.2349\n",
      "Epoch 104/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.2476 - val_loss: 4.9929\n",
      "Epoch 105/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.9717 - val_loss: 4.2676\n",
      "Epoch 106/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.6932 - val_loss: 5.4990\n",
      "Epoch 107/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.2613 - val_loss: 4.2858\n",
      "Epoch 108/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.7893 - val_loss: 4.3991\n",
      "Epoch 109/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.1094 - val_loss: 4.4461\n",
      "Epoch 110/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.0868 - val_loss: 4.3164\n",
      "Epoch 111/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.9810 - val_loss: 4.4469\n",
      "Epoch 112/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.9190 - val_loss: 4.9032\n",
      "Epoch 113/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.0750 - val_loss: 5.7143\n",
      "Epoch 114/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.5232 - val_loss: 4.8489\n",
      "Epoch 115/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.8678 - val_loss: 4.3067\n",
      "Epoch 116/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.9812 - val_loss: 5.7689\n",
      "Epoch 117/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 6.6757 - val_loss: 4.3074\n",
      "Epoch 118/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.7578 - val_loss: 5.6884\n",
      "Epoch 119/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.3748 - val_loss: 4.3031\n",
      "Epoch 120/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.7389 - val_loss: 4.9165\n",
      "Epoch 121/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.0394 - val_loss: 5.1191\n",
      "Epoch 122/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.1620 - val_loss: 4.9520\n",
      "Epoch 123/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.9461 - val_loss: 4.2889\n",
      "Epoch 124/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.7685 - val_loss: 4.8038\n",
      "Epoch 125/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.0089 - val_loss: 4.7657\n",
      "Epoch 126/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.8208 - val_loss: 4.3491\n",
      "Epoch 127/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.7443 - val_loss: 5.0029\n",
      "Epoch 128/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.9322 - val_loss: 4.3859\n",
      "Epoch 129/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.0319 - val_loss: 4.2710\n",
      "Epoch 130/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.8987 - val_loss: 4.4612\n",
      "Epoch 131/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.1936 - val_loss: 4.3655\n",
      "Epoch 132/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.8795 - val_loss: 4.8237\n",
      "Epoch 133/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.8143 - val_loss: 4.4476\n",
      "Epoch 134/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.9611 - val_loss: 4.7952\n",
      "Epoch 135/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.8716 - val_loss: 4.9007\n",
      "Epoch 136/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.0281 - val_loss: 4.4089\n",
      "Epoch 137/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.8801 - val_loss: 5.0304\n",
      "Epoch 138/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.9227 - val_loss: 4.4935\n",
      "Epoch 139/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.6568 - val_loss: 5.3210\n",
      "Epoch 140/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 6.2005 - val_loss: 4.3712\n",
      "Epoch 141/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.1127 - val_loss: 4.3985\n",
      "Epoch 142/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.5206 - val_loss: 5.3039\n",
      "Epoch 143/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 6.1994 - val_loss: 4.6398\n",
      "Epoch 144/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.1571 - val_loss: 4.8707\n",
      "Epoch 145/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.7845 - val_loss: 5.8356\n",
      "Epoch 146/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 6.4665 - val_loss: 5.4593\n",
      "Epoch 147/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 5.1780 - val_loss: 4.4964\n",
      "Epoch 148/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 5.0200 - val_loss: 4.8125\n",
      "Epoch 149/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 4.9741 - val_loss: 5.0340\n",
      "Epoch 150/150\n",
      "12/12 [==============================] - 0s 0us/step - loss: 4.9763 - val_loss: 4.5159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15593538eb8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=10, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "model.fit(X, y, epochs=150, batch_size=10, validation_split=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
